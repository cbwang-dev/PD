---
title: 'P&D ISSP Phase 2 Report'
author: "Chengbin Wang"
fontsize: 10pt
geometry: margin=2cm
classoption: twocolumn
---

### Least Square

Several parameters are concerned in applying least square to design auditory attention decoders.

- *Regularization matrix*.
- *Window length*. Apparently, increasing window size can boost accuracy with a cost of increasing latency. 

The comparisions between different setups of these parameters are shown in Figure ...

### CNN

make sure that you know why you are making certain choices and that you are able to motivate this!!! this is more important than pure accuracy.

- which building blocks
- how many parameters
- regularization
- overfitting
- loss functions

before using deep neural nets, data still has to be normalized.